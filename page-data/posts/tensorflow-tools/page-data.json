{
    "componentChunkName": "component---src-templates-post-template-tsx",
    "path": "/posts/tensorflow-tools",
    "result": {"data":{"markdownRemark":{"html":"<p>There are many tensorflow tools that are not widely known.</p>\n<h2>Freeze Graph</h2>\n<p><a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/freeze_graph.py\" title=\"freeze graph\">Freeze Graph</a> literally freezes the graph.</p>\n<ul>\n<li>Unnecessary nodes will be removed</li>\n<li>Model is one simple protobuf file (weights &#x26; graph definitions)</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">~/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph <span class=\"token punctuation\">\\</span>\n    --input_graph<span class=\"token operator\">=</span>your_graph_definition.pb                  <span class=\"token punctuation\">\\</span>\n    --input_checkpoint<span class=\"token operator\">=</span>your_tensorflow_checkpoint           <span class=\"token punctuation\">\\</span>\n    --input_binary<span class=\"token operator\">=</span>true                                     <span class=\"token punctuation\">\\</span>\n    --output_graph<span class=\"token operator\">=</span>frozen_graph.pb                          <span class=\"token punctuation\">\\</span>\n    --output_node_names<span class=\"token operator\">=</span>Softmax</code></pre></div>\n<p><code class=\"language-text\">input_binary</code> means whether the input graph file is in binary format or not.</p>\n<ul>\n<li>If the file extension ends with <code class=\"language-text\">.pb</code>, it's binary format.</li>\n<li>If the file extension ends with <code class=\"language-text\">.pbtxt</code>, it's a txt format.</li>\n</ul>\n<p><code class=\"language-text\">node_names</code> are the names of tensors.\nFor example, you should be able to retrieve tensors by the name</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># retrieve tensors</span>\nimage_input <span class=\"token operator\">=</span> graph<span class=\"token punctuation\">.</span>get_tensor_by_name<span class=\"token punctuation\">(</span><span class=\"token string\">'image_input:0'</span><span class=\"token punctuation\">)</span>\nkeep_prob <span class=\"token operator\">=</span> graph<span class=\"token punctuation\">.</span>get_tensor_by_name<span class=\"token punctuation\">(</span><span class=\"token string\">'keep_prob:0'</span><span class=\"token punctuation\">)</span>\nsoftmax <span class=\"token operator\">=</span> graph<span class=\"token punctuation\">.</span>get_tensor_by_name<span class=\"token punctuation\">(</span><span class=\"token string\">'Softmax:0'</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># operations</span>\nprob <span class=\"token operator\">=</span> sess<span class=\"token punctuation\">.</span>run<span class=\"token punctuation\">(</span>softmax<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">{</span>image_input<span class=\"token punctuation\">:</span> some_image<span class=\"token punctuation\">,</span> keep_prob<span class=\"token punctuation\">:</span> <span class=\"token number\">1.0</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>And here is the code to load the freeze graph</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">load_graph</span><span class=\"token punctuation\">(</span>graph_file<span class=\"token punctuation\">,</span> use_xla<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    jit_level <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n    config <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>ConfigProto<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">if</span> use_xla<span class=\"token punctuation\">:</span>\n        jit_level <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>OptimizerOptions<span class=\"token punctuation\">.</span>ON_1\n        config<span class=\"token punctuation\">.</span>graph_options<span class=\"token punctuation\">.</span>optimizer_options<span class=\"token punctuation\">.</span>global_jit_level <span class=\"token operator\">=</span> jit_level\n\n    <span class=\"token keyword\">with</span> tf<span class=\"token punctuation\">.</span>Session<span class=\"token punctuation\">(</span>graph<span class=\"token operator\">=</span>tf<span class=\"token punctuation\">.</span>Graph<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> config<span class=\"token operator\">=</span>config<span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> sess<span class=\"token punctuation\">:</span>\n        gd <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>GraphDef<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n        <span class=\"token keyword\">with</span> tf<span class=\"token punctuation\">.</span>gfile<span class=\"token punctuation\">.</span>Open<span class=\"token punctuation\">(</span>graph_file<span class=\"token punctuation\">,</span> <span class=\"token string\">'rb'</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> f<span class=\"token punctuation\">:</span>\n            data <span class=\"token operator\">=</span> f<span class=\"token punctuation\">.</span>read<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n            gd<span class=\"token punctuation\">.</span>ParseFromString<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span>\n\n        tf<span class=\"token punctuation\">.</span>import_graph_def<span class=\"token punctuation\">(</span>gd<span class=\"token punctuation\">,</span> name<span class=\"token operator\">=</span><span class=\"token string\">''</span><span class=\"token punctuation\">)</span>\n\n        <span class=\"token comment\"># unnecessary: only to see how many operations are in the model</span>\n        ops <span class=\"token operator\">=</span> sess<span class=\"token punctuation\">.</span>graph<span class=\"token punctuation\">.</span>get_operations<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        n_ops <span class=\"token operator\">=</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>ops<span class=\"token punctuation\">)</span>\n\n        <span class=\"token keyword\">return</span> sess<span class=\"token punctuation\">.</span>graph<span class=\"token punctuation\">,</span> ops</code></pre></div>\n<p>After freezing, the number of operation has reduced by 88%.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">sess<span class=\"token punctuation\">,</span> base_ops <span class=\"token operator\">=</span> load_graph<span class=\"token punctuation\">(</span><span class=\"token string\">'base_graph.pb'</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>base_ops<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># 2165</span>\n\nsess<span class=\"token punctuation\">,</span> frozen_ops <span class=\"token operator\">=</span> load_graph<span class=\"token punctuation\">(</span><span class=\"token string\">'frozen_graph.pb'</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>frozen_ops<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># 245</span></code></pre></div>\n<h2>Optimize for Inference</h2>\n<p>For inference, it can be further optimized through <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/optimize_for_inference.py\" title=\"optimize inference\">Optimize for Inference</a></p>\n<ul>\n<li>Some operations are not necessary for inference\n<ul>\n<li>For example, batch normalization can be removed after extracting mean and std</li>\n</ul>\n</li>\n<li>Many operations can be fused into one\n<ul>\n<li>For example, 3 steps (CNN - BN - RELU) can be fused into one step (CNNBNRELU)</li>\n</ul>\n</li>\n</ul>\n<h3>Usage</h3>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">bazel build tensorflow/python/tools:optimize_for_inference <span class=\"token operator\">&amp;&amp;</span> <span class=\"token punctuation\">\\</span>\nbazel-bin/tensorflow/python/tools/optimize_for_inference      <span class=\"token punctuation\">\\</span>\n      --input<span class=\"token operator\">=</span>frozen_inception_graph.pb                       <span class=\"token punctuation\">\\</span>\n      --output<span class=\"token operator\">=</span>optimized_inception_graph.pb                   <span class=\"token punctuation\">\\</span>\n      --frozen_graph<span class=\"token operator\">=</span>True                                     <span class=\"token punctuation\">\\</span>\n      --input_names<span class=\"token operator\">=</span>Mul                                       <span class=\"token punctuation\">\\</span>\n      --output_names<span class=\"token operator\">=</span>softmax</code></pre></div>\n<h3>Result</h3>\n<p>Now the number of operation has reduced to 200.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">sess<span class=\"token punctuation\">,</span> optimized_ops <span class=\"token operator\">=</span> load_graph<span class=\"token punctuation\">(</span><span class=\"token string\">'optimized_graph.pb'</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>optimized_ops<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># 200</span></code></pre></div>\n<h2>Graph Transform</h2>\n<p><a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/graph_transforms/README.md\">Graph Transform</a> allows to transform the graph.</p>\n<p>For example,</p>\n<ul>\n<li>Float to Int</li>\n<li>32 bits to 8 bits</li>\n</ul>\n<p>There are so much less data. Now it runs so much faster.</p>\n<h3>Is it okay?</h3>\n<p>For training, back propagation requires significant digits.\nFor inference, it's not necessary since we are interested in the highest output (label) not the value itself.</p>\n<h3>Usage</h3>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">bazel build tensorflow/tools/graph_transforms:transform_graph\nbazel-bin/tensorflow/tools/graph_transforms/transform_graph <span class=\"token punctuation\">\\</span>\n      --in_graph<span class=\"token operator\">=</span>tensorflow_inception_graph.pb              <span class=\"token punctuation\">\\</span>\n      --out_graph<span class=\"token operator\">=</span>optimized_inception_graph.pb              <span class=\"token punctuation\">\\</span>\n      --inputs<span class=\"token operator\">=</span><span class=\"token string\">'Mul:0'</span>                                      <span class=\"token punctuation\">\\</span>\n      --outputs<span class=\"token operator\">=</span><span class=\"token string\">'softmax:0'</span>                                 <span class=\"token punctuation\">\\</span>\n      --transforms<span class=\"token operator\">=</span><span class=\"token string\">'\n          strip_unused_nodes(type=float, shape=\"1,299,299,3\")\n          remove_nodes(op=Identity, op=CheckNumerics)\n          fold_old_batch_norms\n          '</span></code></pre></div>\n<h3>Result</h3>\n<p>Note that the number of operations has increased, but the model runs super fast with lower bits.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">sess<span class=\"token punctuation\">,</span> eightbit_ops <span class=\"token operator\">=</span> load_graph<span class=\"token punctuation\">(</span><span class=\"token string\">'eightbit_graph.pb'</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>optimized_ops<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># 425</span></code></pre></div>\n<h2>AOT &#x26; JIT</h2>\n<p>Tensorflow supports AOT and JIT compilation.</p>\n<ul>\n<li>AOT stands for \"Ahead Of Time\"</li>\n<li>JIT stands for \"Just In Time\"</li>\n</ul>\n<p>Furthermore, it can be used not only for inference but also for training as well.</p>\n<h3>Usage</h3>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\"><span class=\"token comment\"># Create a TensorFlow configuration object.</span>\nconfig <span class=\"token operator\">=</span> tf.Config<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># JIT level, this can be set to ON_1 or ON_2</span>\njit_level <span class=\"token operator\">=</span> tf.OptimizerOptions.ON_1\nconfig.graph_options.optimizer_options.global_jit_level <span class=\"token operator\">=</span> jit_level\n\n<span class=\"token comment\"># Open a session with the config</span>\nwith tf.Session<span class=\"token punctuation\">(</span>config<span class=\"token operator\">=</span>config<span class=\"token punctuation\">)</span> as sess:\n    <span class=\"token punctuation\">..</span>.</code></pre></div>","excerpt":"There are many tensorflow tools that are not widely known. Freeze Graph Freeze Graph literally freezes the graph. Unnecessary nodes will be…","frontmatter":{"date":"November 27, 2017","title":"Tensorflow tools","keywords":null,"description":null},"fields":{"slug":"posts/tensorflow-tools"}}},"pageContext":{"slug":"posts/tensorflow-tools"}},
    "staticQueryHashes": []}